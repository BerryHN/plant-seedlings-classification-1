{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scripts.util import f1_micro\n",
    "\n",
    "OUTPUT_DIR = \"./output_data\"\n",
    "log_file = os.path.join(OUTPUT_DIR, \"log.csv\")\n",
    "dataset = \"./datasets/train.csv\"\n",
    "\n",
    "model_filepath = os.path.join(OUTPUT_DIR, \"plant_vgg19.h5\")\n",
    "weights_filepath = os.path.join(OUTPUT_DIR, \"plant_vgg19_weights.h5\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# No of split for skfold cross validation\n",
    "n_splits = 5\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "shuffle = True\n",
    "\n",
    "# Read pre-generated dataset comprising of 3 columns (file, species, species_id)\n",
    "df = pd.read_csv(dataset).sample(frac=1.0)\n",
    "\n",
    "# number of classes\n",
    "n_classes = df.species.nunique()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize all images\n",
    "print(\"Loading images...\")\n",
    "all_imgs = []\n",
    "for filename in df.file:\n",
    "    img = image.load_img(filename, target_size=(299, 299, 3))\n",
    "    img = image.img_to_array(img)\n",
    "    all_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "X = np.array(all_imgs)  # Matrix of (m x 299 x 299 x 3)\n",
    "X = preprocess_input(X)  # Preprocess using VGG19 preprocess_input\n",
    "y = df.as_matrix(columns=[\"species_id\"])  # Convert target to numpy array of m x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# include_top is used to remove all the layers after block conv5\n",
    "model = VGG19(include_top=False, input_shape=img.shape)\n",
    "\n",
    "# Freeze all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# re-add the removed layers\n",
    "x = model.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
    "x = Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n",
    "x = Dense(n_classes, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "# Redefine the model\n",
    "model = Model(inputs=model.input, outputs=x, name=\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[f1_micro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a splitter\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Training\n",
    "print(\"Start cross-validation training...\")\n",
    "histories = []\n",
    "for train, val in skf.split(X, y):\n",
    "    Xtrain = X[train, :]\n",
    "    ytrain = to_categorical(y[train, :])\n",
    "    Xval = X[val, :]\n",
    "    yval = to_categorical(y[val, :])\n",
    "    history = model.fit(Xtrain, ytrain, batch_size=batch_size, epochs=epochs, validation_data=(Xval, yval))\n",
    "    histories.append(history)\n",
    "\n",
    "# Full training\n",
    "print(\"Full training...\")\n",
    "history = model.fit(X, y, batch_size=batch_size, epochs=epochs)\n",
    "histories.append(history)\n",
    "\n",
    "print(\"Save whole model...\")\n",
    "model.save(model_filepath)\n",
    "\n",
    "print(\"Save weights of the model\")\n",
    "model.save(weights_filepath)\n",
    "\n",
    "with open(log_file, \"w\") as f:\n",
    "    json.dump(histories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant-seedlings-classification",
   "language": "python",
   "name": "plant-seedlings-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
